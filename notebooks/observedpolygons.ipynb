{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extractions for observed forest disturbances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required modules\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import rasterio as rst\n",
    "from rasterstats import zonal_stats\n",
    "import glob\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import multiprocessing\n",
    "from multiprocessing import Pool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EFFIS data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The id column is cat in case earlier versions of the extractions need to be traced back.\n",
    "There was a problem with the year 2017. The folder amended files contains an amended version of the dataset.\n",
    "Original files provied by guido are stored in the external hard drive marcodata2019 under ESSDrive/datasets/guido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in polygon data\n",
    "results_final = []\n",
    "for filep in glob.glob('/mnt/data1tb/Dropbox/Forest@risk/polygonsGRASS/EFFIS20205year_amended/*.shp'):\n",
    "    # read in polygon\n",
    "    tmpp = gpd.read_file(filep)\n",
    "    # append polygon to list\n",
    "    results_final.append(tmpp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Static datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PFTs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through raster files\n",
    "for filer in glob.glob('/mnt/data1tb/rasters/EU/pfts/*.tif'):\n",
    "        # get out names for variable of interest\n",
    "        varname = os.path.basename(filer).split('.')[0]\n",
    "        # print variable name\n",
    "        print(varname)\n",
    "        # open raster with rasterio\n",
    "        tmpr = rst.open(filer)\n",
    "        # convert into array\n",
    "        tmpar = tmpr.read(1)\n",
    "        # Loop through vector files\n",
    "        for filep in results_final:\n",
    "            # zonal statisticfileslegs (sum)\n",
    "            stats = zonal_stats(filep, tmpar, affine=tmpr.transform, stats=['sum'], all_touched=True,nodata=tmpr.nodata)\n",
    "            # zonal statistics (count)\n",
    "            totpixels = zonal_stats(filep, tmpar, affine=tmpr.transform, stats=['count'], all_touched=True,nodata=tmpr.nodata)\n",
    "            # convert dictionaries into lists\n",
    "            stats1 = [val for dic in stats for val in dic.values()]\n",
    "            totpixels1 = [val for dic in totpixels for val in dic.values()]\n",
    "            # store in pandas dataframe\n",
    "            filep[varname] = stats1\n",
    "            # total number of pixels\n",
    "            varname1 = varname + '_pixels'\n",
    "            filep[varname1] = totpixels1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Continuous variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through raster files\n",
    "for filer in glob.glob('/mnt/data1tb/rasters/EU/static/*.tif'):\n",
    "    # get out names for variable of interest\n",
    "    varname = os.path.basename(filer).split('.')[0]\n",
    "    # print variable name\n",
    "    print(varname)\n",
    "    # open raster with rasterio\n",
    "    tmpr = rst.open(filer)\n",
    "    # convert into array\n",
    "    tmpar = tmpr.read(1)\n",
    "    # Loop through vector files\n",
    "    for filep in results_final:\n",
    "        # zonal statistics (mean)\n",
    "        stats = zonal_stats(filep, tmpar, affine=tmpr.transform, stats=['mean'], all_touched=True, nodata=tmpr.nodata)\n",
    "        # convert dictionaries into lists\n",
    "        stats1 = [val for dic in stats for val in dic.values()]\n",
    "        # store in pandas dataframe\n",
    "        filep[varname] = stats1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EFI tree cover maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through raster files\n",
    "for filer in glob.glob('/mnt/data1tb/rasters/EU/EFItrees/*.tif'):\n",
    "        # open raster with rasterio\n",
    "        tmpr = rst.open(filer)\n",
    "        # convert into array\n",
    "        tmpar = tmpr.read(1)\n",
    "        # get out names for variable of interest\n",
    "        varname = os.path.basename(filer).split('.')[0]\n",
    "        print(varname)\n",
    "        # Loop through vector files\n",
    "        for filep in results_final:\n",
    "            # zonal statistics (mean)\n",
    "            stats = zonal_stats(filep, tmpar, affine=tmpr.transform, stats=['sum'], all_touched=True, nodata=tmpr.nodata)\n",
    "            # convert dictionaries into lists\n",
    "            stats1 = [val for dic in stats for val in dic.values()]\n",
    "            # store in pandas dataframe\n",
    "            filep[varname] = stats1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Spatio-temporal datasets "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Event-scale variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through raster files\n",
    "for filer in glob.glob('/mnt/data1tb/rasters/EU/dynamic1_Nov19/*.tif'):\n",
    "    # open raster with rasterio\n",
    "    tmpr = rst.open(filer)\n",
    "    # convert into array\n",
    "    tmpar = tmpr.read(1)\n",
    "    # if integer convert into floating point\n",
    "    if ('float' in tmpar.dtype.type.__name__)==False:\n",
    "        # set array values to floating\n",
    "        tmpar = tmpar.astype('float')\n",
    "    # exception for Aridity Index (lack consistent naming)\n",
    "    if 'AI' in os.path.basename(filer):\n",
    "        varname = os.path.basename(filer).split('.')[0].split('_')[0]\n",
    "        year = os.path.basename(filer).split('.')[0].split('_')[1]\n",
    "    # contains population name\n",
    "    elif 'pop' in os.path.basename(filer):\n",
    "           varname = os.path.basename(filer).split('.')[0].split('2')[0]\n",
    "           numbs = re.findall('\\d+', os.path.basename(filer).split('.')[0])\n",
    "           # extract the number with the longest number of digits\n",
    "           year = max(numbs, key=len)\n",
    "    elif 'suppressionp' in os.path.basename(filer) or 'ignitionp' in os.path.basename(filer):\n",
    "               varname = os.path.basename(filer).split('.')[0].split('_')[0]\n",
    "               numbs = re.findall('\\d+', os.path.basename(filer).split('.')[0])\n",
    "               # extract the number with the longest number of digits\n",
    "               year = max(numbs, key=len)\n",
    "    else:\n",
    "        # get out names for variable of interest\n",
    "        varnametmp = os.path.basename(filer).split('.')[0]\n",
    "        varname = varnametmp.split('_')[0] + \"_\" + varnametmp.split('_')[1] + \"_\" + varnametmp.split('_')[3]\n",
    "        # get out name for variable of interest\n",
    "        # parse numbers (could be year, resolution or season!)\n",
    "        numbs = re.findall('\\d+', os.path.basename(filer).split('.')[0])\n",
    "        # extract the number with the longest number of digits\n",
    "        year = max(numbs, key=len)\n",
    "    # match year with polygon\n",
    "    for filep in results_final:\n",
    "        # create year filter\n",
    "        if (str(int(filep.yearssn.unique()[0])) == year):\n",
    "            # zonal statistics (mean)\n",
    "            stats = zonal_stats(filep, tmpar, affine=tmpr.transform, stats=['mean'], all_touched=True,nodata=tmpr.nodata)\n",
    "            # convert dictionaries into lists\n",
    "            stats1 = [val for dic in stats for val in dic.values()]\n",
    "            # store in pandas dataframe\n",
    "            filep[varname] = stats1\n",
    "        else:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Legacy effects: includes legacy effects back to 5 years before the year of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exclude population density and fire suppression and ignition probabilities\n",
    "filesleg = [fn for fn in glob.glob('/mnt/data1tb/rasters/EU/dynamic1_Nov19/*.tif') if\n",
    " 'pop' not in os.path.basename(fn) and 'suppressionp' not in os.path.basename(fn) and 'ignitionp' not in os.path.basename(fn)]\n",
    "\n",
    "# Loop through raster files\n",
    "for filer in filesleg:\n",
    "    # exception for Aridity Index (lack consistent naming)\n",
    "    if 'AI' in os.path.basename(filer):\n",
    "        varname = os.path.basename(filer).split('.')[0].split('_')[0]\n",
    "        year = os.path.basename(filer).split('.')[0].split('_')[1]\n",
    "    else:\n",
    "        # get out names for variable of interest\n",
    "        varnametmp = os.path.basename(filer).split('.')[0]\n",
    "        varname = varnametmp.split('_')[0] + \"_\" + varnametmp.split('_')[1] + \"_\" + varnametmp.split('_')[3]\n",
    "        # parse numbers (could be year, resolution or season!)\n",
    "        numbs = re.findall('\\d+', os.path.basename(filer).split('.')[0])\n",
    "        # extract the number with the longest number of digits\n",
    "        year = int(max(numbs, key=len))\n",
    "        if year <= 1999:\n",
    "           pass\n",
    "        else:\n",
    "            # --- create list of lagged rasters --- (goes back 5 years)\n",
    "            rastlags = {} \n",
    "            lags = list(range(1,5+1))\n",
    "            for lag in lags:\n",
    "                # strings for lagged effects and year of interest\n",
    "                year_m1 = str(year-lag)\n",
    "                # path for raster year\n",
    "                fpathym1 = '/mnt/data1tb/rasters/EU/dynamic1_Nov19/' + str.replace(varnametmp, str(year),year_m1)+'.tif'\n",
    "                # open raster with rasterio\n",
    "                tmpr = rst.open(fpathym1)\n",
    "                # convert into array\n",
    "                tmpar = tmpr.read(1)\n",
    "                # if integer convert into floating point\n",
    "                if ('float' in tmpar.dtype.type.__name__) == False:             \n",
    "                    # set array values to floating\n",
    "                    tmpar = tmpar.astype('float')\n",
    "                # append raster to list\n",
    "                rastlags[year_m1] = tmpar\n",
    "            # --- go through each set of polygons divided by year\n",
    "            for filep in results_final:\n",
    "                # create year filter\n",
    "                if (filep.yearssn.unique()[0] == year):\n",
    "                    # --- zonal statistics for lagged effects\n",
    "                    for onerast in rastlags:\n",
    "                        # zonal statistics (mean)\n",
    "                        stats = zonal_stats(filep, rastlags[onerast], affine=tmpr.transform, stats=['mean'], all_touched=True,nodata=tmpr.nodata)\n",
    "                        # convert dictionaries into lists\n",
    "                        stats1 = [val for dic in stats for val in dic.values()]\n",
    "                        # convert dictionaries into lists\n",
    "                        filep[varname+'_ym'+str(year - int(onerast))] = stats1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Write out file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate list of pandas dataframes\n",
    "results_final1 = pd.concat(results_final)\n",
    "# delete geometry column\n",
    "results_final1 = results_final1.drop(['geometry'], axis=1)\n",
    "# write results as csv file\n",
    "results_final1.to_csv('/mnt/data1tb/Dropbox/Forest@risk/scripts/y2020/R/outdata/observed/EFFIS_OBSERVED.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WINDFOR data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The id column is Id_poly in case earlier versions of the extractions need to be traced back."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in polygon data\n",
    "results_final = []\n",
    "for filep in glob.glob('/mnt/data1tb/rasters/guido/WIND/*.shp'):\n",
    "    # read in polygon\n",
    "    tmpp = gpd.read_file(filep)\n",
    "    # append polygon to list\n",
    "    results_final.append(tmpp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Static datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PFTs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through raster files\n",
    "for filer in glob.glob('/mnt/data1tb/rasters/EU/pfts/*.tif'):\n",
    "        # get out names for variable of interest\n",
    "        varname = os.path.basename(filer).split('.')[0]\n",
    "        # print variable name\n",
    "        print(varname)\n",
    "        # open raster with rasterio\n",
    "        tmpr = rst.open(filer)\n",
    "        # convert into array\n",
    "        tmpar = tmpr.read(1)\n",
    "        # Loop through vector files\n",
    "        for filep in results_final:\n",
    "            # zonal statisticfileslegs (sum)\n",
    "            stats = zonal_stats(filep, tmpar, affine=tmpr.transform, stats=['sum'], all_touched=True,nodata=tmpr.nodata)\n",
    "            # zonal statistics (count)\n",
    "            totpixels = zonal_stats(filep, tmpar, affine=tmpr.transform, stats=['count'], all_touched=True,nodata=tmpr.nodata)\n",
    "            # convert dictionaries into lists\n",
    "            stats1 = [val for dic in stats for val in dic.values()]\n",
    "            totpixels1 = [val for dic in totpixels for val in dic.values()]\n",
    "            # store in pandas dataframe\n",
    "            filep[varname] = stats1\n",
    "            # total number of pixels\n",
    "            varname1 = varname + '_pixels'\n",
    "            filep[varname1] = totpixels1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Continuous variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through raster files\n",
    "for filer in glob.glob('/mnt/data1tb/rasters/EU/static/*.tif'):\n",
    "    # get out names for variable of interest\n",
    "    varname = os.path.basename(filer).split('.')[0]\n",
    "    # print variable name\n",
    "    print(varname)\n",
    "    # open raster with rasterio\n",
    "    tmpr = rst.open(filer)\n",
    "    # convert into array\n",
    "    tmpar = tmpr.read(1)\n",
    "    # Loop through vector files\n",
    "    for filep in results_final:\n",
    "        # zonal statistics (mean)\n",
    "        stats = zonal_stats(filep, tmpar, affine=tmpr.transform, stats=['mean'], all_touched=True, nodata=tmpr.nodata)\n",
    "        # convert dictionaries into lists\n",
    "        stats1 = [val for dic in stats for val in dic.values()]\n",
    "        # store in pandas dataframe\n",
    "        filep[varname] = stats1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EFI tree cover maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through raster files\n",
    "for filer in glob.glob('/mnt/data1tb/rasters/EU/EFItrees/*.tif'):\n",
    "        # open raster with rasterio\n",
    "        tmpr = rst.open(filer)\n",
    "        # convert into array\n",
    "        tmpar = tmpr.read(1)\n",
    "        # get out names for variable of interest\n",
    "        varname = os.path.basename(filer).split('.')[0]\n",
    "        print(varname)\n",
    "        # Loop through vector files\n",
    "        for filep in results_final:\n",
    "            # zonal statistics (mean)\n",
    "            stats = zonal_stats(filep, tmpar, affine=tmpr.transform, stats=['sum'], all_touched=True, nodata=tmpr.nodata)\n",
    "            # convert dictionaries into lists\n",
    "            stats1 = [val for dic in stats for val in dic.values()]\n",
    "            # store in pandas dataframe\n",
    "            filep[varname] = stats1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Spatio-temporal datasets "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Event-scale variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through raster files\n",
    "for filer in glob.glob('/mnt/data1tb/rasters/EU/dynamic1_Nov19/*.tif'):\n",
    "    # open raster with rasterio\n",
    "    tmpr = rst.open(filer)\n",
    "    # convert into array\n",
    "    tmpar = tmpr.read(1)\n",
    "    # if integer convert into floating point\n",
    "    if ('float' in tmpar.dtype.type.__name__)==False:\n",
    "        # set array values to floating\n",
    "        tmpar = tmpar.astype('float')\n",
    "    # exception for Aridity Index (lack consistent naming)\n",
    "    if 'AI' in os.path.basename(filer):\n",
    "        varname = os.path.basename(filer).split('.')[0].split('_')[0]\n",
    "        year = os.path.basename(filer).split('.')[0].split('_')[1]\n",
    "    # contains population name\n",
    "    elif 'pop' in os.path.basename(filer):\n",
    "           varname = os.path.basename(filer).split('.')[0].split('2')[0]\n",
    "           numbs = re.findall('\\d+', os.path.basename(filer).split('.')[0])\n",
    "           # extract the number with the longest number of digits\n",
    "           year = max(numbs, key=len)\n",
    "    elif 'suppressionp' in os.path.basename(filer) or 'ignitionp' in os.path.basename(filer):\n",
    "               varname = os.path.basename(filer).split('.')[0].split('_')[0]\n",
    "               numbs = re.findall('\\d+', os.path.basename(filer).split('.')[0])\n",
    "               # extract the number with the longest number of digits\n",
    "               year = max(numbs, key=len)\n",
    "    else:\n",
    "        # get out names for variable of interest\n",
    "        varnametmp = os.path.basename(filer).split('.')[0]\n",
    "        varname = varnametmp.split('_')[0] + \"_\" + varnametmp.split('_')[1] + \"_\" + varnametmp.split('_')[3]\n",
    "        # get out name for variable of interest\n",
    "        # parse numbers (could be year, resolution or season!)\n",
    "        numbs = re.findall('\\d+', os.path.basename(filer).split('.')[0])\n",
    "        # extract the number with the longest number of digits\n",
    "        year = max(numbs, key=len)\n",
    "        # match year with polygon\n",
    "        for filep in results_final:\n",
    "            # create year filter\n",
    "            if (str(filep.yearssn.unique()[0]) == year):\n",
    "                # zonal statistics (mean)\n",
    "                stats = zonal_stats(filep, tmpar, affine=tmpr.transform, stats=['mean'], all_touched=True,nodata=tmpr.nodata)\n",
    "                # convert dictionaries into lists\n",
    "                stats1 = [val for dic in stats for val in dic.values()]\n",
    "                # store in pandas dataframe\n",
    "                filep[varname] = stats1\n",
    "            else:\n",
    "                pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Legacy effects "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exclude population density and fire suppression and ignition probabilities\n",
    "filesleg = [fn for fn in glob.glob('/mnt/data1tb/rasters/EU/dynamic1_Nov19/*.tif') if\n",
    " 'pop' not in os.path.basename(fn) and 'suppressionp' not in os.path.basename(fn) and 'ignitionp' not in os.path.basename(fn)]\n",
    "\n",
    "# Loop through raster files\n",
    "for filer in filesleg:\n",
    "    # exception for Aridity Index (lack consistent naming)\n",
    "    if 'AI' in os.path.basename(filer):\n",
    "        varname = os.path.basename(filer).split('.')[0].split('_')[0]\n",
    "        year = os.path.basename(filer).split('.')[0].split('_')[1]\n",
    "    else:\n",
    "        # get out names for variable of interest\n",
    "        varnametmp = os.path.basename(filer).split('.')[0]\n",
    "        varname = varnametmp.split('_')[0] + \"_\" + varnametmp.split('_')[1] + \"_\" + varnametmp.split('_')[3]\n",
    "        # parse numbers (could be year, resolution or season!)\n",
    "        numbs = re.findall('\\d+', os.path.basename(filer).split('.')[0])\n",
    "        # extract the number with the longest number of digits\n",
    "        year = int(max(numbs, key=len))\n",
    "        if year<= 1999:\n",
    "           pass\n",
    "        else:\n",
    "            #print(varnametmp)\n",
    "            # extract year-1 from name\n",
    "            year_m1 = str(year-1)\n",
    "            year = str(year)\n",
    "            # path for raster year -1\n",
    "            fpathym1 = '/mnt/data1tb/rasters/EU/dynamic1_Nov19/' + str.replace(varnametmp, year, year_m1) + '.tif'\n",
    "            # open raster with rasterio\n",
    "            tmpr = rst.open(fpathym1)\n",
    "            # convert into array\n",
    "            tmpar = tmpr.read(1)\n",
    "            # if integer convert into floating point\n",
    "            if ('float' in tmpar.dtype.type.__name__) == False:\n",
    "               # set array values to floating\n",
    "               tmpar = tmpar.astype('float')\n",
    "            # match year with polygon\n",
    "            for filep in results_final:\n",
    "                # create year filter\n",
    "                if (str(filep.yearssn.unique()[0]) == year):\n",
    "                    # zonal statistics (mean)\n",
    "                    stats = zonal_stats(filep, tmpar, affine=tmpr.transform, stats=['mean'], all_touched=True,nodata=tmpr.nodata)\n",
    "                    # convert dictionaries into lists\n",
    "                    stats1 = [val for dic in stats for val in dic.values()]\n",
    "                    # store in pandas dataframe\n",
    "                    filep[varname+'_ym1'] = stats1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate list of pandas dataframes\n",
    "results_final1 = pd.concat(results_final)\n",
    "# delete geometry column\n",
    "results_final1 = results_final1.drop(['geometry'], axis=1)\n",
    "# write results as csv file\n",
    "results_final1.to_csv('/home/marco/Desktop/WIND_OBSERVED.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## INSECT data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The id column is cat in case earlier versions of the extractions need to be traced back."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in polygon data\n",
    "results_final = []\n",
    "for filep in glob.glob('/mnt/data1tb/Dropbox/Forest@risk/polygonsGRASS/USDA/*.shp'):\n",
    "    # read in polygon\n",
    "    tmpp = gpd.read_file(filep)\n",
    "    # append polygon to list\n",
    "    results_final.append(tmpp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PFTs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through raster files\n",
    "for filer in glob.glob('/mnt/data1tb/rasters/EU/pfts/*.tif'):\n",
    "        # get out names for variable of interest\n",
    "        varname = os.path.basename(filer).split('.')[0]\n",
    "        # print variable name\n",
    "        print(varname)\n",
    "        # open raster with rasterio\n",
    "        tmpr = rst.open(filer)\n",
    "        # convert into array\n",
    "        tmpar = tmpr.read(1)\n",
    "        # Loop through vector files\n",
    "        for filep in results_final:\n",
    "            # zonal statisticfileslegs (sum)\n",
    "            stats = zonal_stats(filep, tmpar, affine=tmpr.transform, stats=['sum'], all_touched=True,nodata=tmpr.nodata)\n",
    "            # zonal statistics (count)\n",
    "            totpixels = zonal_stats(filep, tmpar, affine=tmpr.transform, stats=['count'], all_touched=True,nodata=tmpr.nodata)\n",
    "            # convert dictionaries into lists\n",
    "            stats1 = [val for dic in stats for val in dic.values()]\n",
    "            totpixels1 = [val for dic in totpixels for val in dic.values()]\n",
    "            # store in pandas dataframe\n",
    "            filep[varname] = stats1\n",
    "            # total number of pixels\n",
    "            varname1 = varname + '_pixels'\n",
    "            filep[varname1] = totpixels1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Continuous variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through raster files\n",
    "for filer in glob.glob('/mnt/data1tb/rasters/NA/static/*.tif'):\n",
    "    # get out names for variable of interest\n",
    "    varname = os.path.basename(filer).split('.')[0]\n",
    "    # print variable name\n",
    "    print(varname)\n",
    "    # open raster with rasterio\n",
    "    tmpr = rst.open(filer)\n",
    "    # convert into array\n",
    "    tmpar = tmpr.read(1)\n",
    "    # Loop through vector files\n",
    "    for filep in results_final:\n",
    "        # zonal statistics (mean)\n",
    "        stats = zonal_stats(filep, tmpar, affine=tmpr.transform, stats=['mean'], all_touched=True, nodata=tmpr.nodata)\n",
    "        # convert dictionaries into lists\n",
    "        stats1 = [val for dic in stats for val in dic.values()]\n",
    "        # store in pandas dataframe\n",
    "        filep[varname] = stats1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Spatio-temporal datasets "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Event-scale variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through raster files\n",
    "for filer in glob.glob('/mnt/data1tb/rasters/NA/dynamic/*.tif'):\n",
    "    # open raster with rasterio\n",
    "    tmpr = rst.open(filer)\n",
    "    # convert into array\n",
    "    tmpar = tmpr.read(1)\n",
    "    # if integer convert into floating point\n",
    "    if ('float' in tmpar.dtype.type.__name__)==False:\n",
    "        # set array values to floating\n",
    "        tmpar = tmpar.astype('float')\n",
    "    # exception for Aridity Index (lack consistent naming)\n",
    "    if 'AI' in os.path.basename(filer):\n",
    "        varname = os.path.basename(filer).split('.')[0].split('_')[0]\n",
    "        year = os.path.basename(filer).split('.')[0].split('_')[1]\n",
    "    # contains population name\n",
    "    elif 'pop' in os.path.basename(filer):\n",
    "           varname = os.path.basename(filer).split('.')[0].split('2')[0]\n",
    "           numbs = re.findall('\\d+', os.path.basename(filer).split('.')[0])\n",
    "           # extract the number with the longest number of digits\n",
    "           year = max(numbs, key=len)\n",
    "    elif 'suppressionp' in os.path.basename(filer) or 'ignitionp' in os.path.basename(filer):\n",
    "               varname = os.path.basename(filer).split('.')[0].split('_')[0]\n",
    "               numbs = re.findall('\\d+', os.path.basename(filer).split('.')[0])\n",
    "               # extract the number with the longest number of digits\n",
    "               year = max(numbs, key=len)\n",
    "    else:\n",
    "        # get out names for variable of interest\n",
    "        varnametmp = os.path.basename(filer).split('.')[0]\n",
    "        varname = varnametmp.split('_')[0] + \"_\" + varnametmp.split('_')[1] + \"_\" + varnametmp.split('_')[3]\n",
    "        # get out name for variable of interest\n",
    "        # parse numbers (could be year, resolution or season!)\n",
    "        numbs = re.findall('\\d+', os.path.basename(filer).split('.')[0])\n",
    "        # extract the number with the longest number of digits\n",
    "        year = max(numbs, key=len)\n",
    "        # match year with polygon\n",
    "    # match year with polygon\n",
    "    for filep in results_final:\n",
    "        # create year filter\n",
    "        if (str(int(filep.yearssn.unique()[0])) == year):\n",
    "            # zonal statistics (mean)\n",
    "            stats = zonal_stats(filep, tmpar, affine=tmpr.transform, stats=['mean'], all_touched=True,nodata=tmpr.nodata)\n",
    "            # convert dictionaries into lists\n",
    "            stats1 = [val for dic in stats for val in dic.values()]\n",
    "            # store in pandas dataframe\n",
    "            filep[varname] = stats1\n",
    "        else:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Legacy effects "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exclude population density and fire suppression and ignition probabilities\n",
    "filesleg = [fn for fn in glob.glob('/mnt/data1tb/rasters/EU/dynamic1_Nov19/*.tif') if\n",
    " 'pop' not in os.path.basename(fn) and 'suppressionp' not in os.path.basename(fn) and 'ignitionp' not in os.path.basename(fn)]\n",
    "\n",
    "# Loop through raster files\n",
    "for filer in filesleg:\n",
    "    # exception for Aridity Index (lack consistent naming)\n",
    "    if 'AI' in os.path.basename(filer):\n",
    "        varname = os.path.basename(filer).split('.')[0].split('_')[0]\n",
    "        year = os.path.basename(filer).split('.')[0].split('_')[1]\n",
    "    else:\n",
    "        # get out names for variable of interest\n",
    "        varnametmp = os.path.basename(filer).split('.')[0]\n",
    "        varname = varnametmp.split('_')[0] + \"_\" + varnametmp.split('_')[1] + \"_\" + varnametmp.split('_')[3]\n",
    "        # parse numbers (could be year, resolution or season!)\n",
    "        numbs = re.findall('\\d+', os.path.basename(filer).split('.')[0])\n",
    "        # extract the number with the longest number of digits\n",
    "        year = int(max(numbs, key=len))\n",
    "        if year<= 1999:\n",
    "           pass\n",
    "        else:\n",
    "            #print(varnametmp)\n",
    "            # extract year-1 from name\n",
    "            year_m1 = str(year-1)\n",
    "            year = str(year)\n",
    "            # path for raster year -1\n",
    "            fpathym1 = '/mnt/data1tb/rasters/EU/dynamic1_Nov19/' + str.replace(varnametmp, year, year_m1) + '.tif'\n",
    "            # open raster with rasterio\n",
    "            tmpr = rst.open(fpathym1)\n",
    "            # convert into array\n",
    "            tmpar = tmpr.read(1)\n",
    "            # if integer convert into floating point\n",
    "            if ('float' in tmpar.dtype.type.__name__) == False:\n",
    "               # set array values to floating\n",
    "               tmpar = tmpar.astype('float')\n",
    "            # match year with polygon\n",
    "            for filep in results_final:\n",
    "                # create year filter\n",
    "                if (str(filep.yearssn.unique()[0]) == year):\n",
    "                    # zonal statistics (mean)\n",
    "                    stats = zonal_stats(filep, tmpar, affine=tmpr.transform, stats=['mean'], all_touched=True,nodata=tmpr.nodata)\n",
    "                    # convert dictionaries into lists\n",
    "                    stats1 = [val for dic in stats for val in dic.values()]\n",
    "                    # store in pandas dataframe\n",
    "                    filep[varname+'_ym1'] = stats1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----Dynamic maps: legacy effects\n",
    "\n",
    "# exclude population density and fire suppression and ignition probabilities\n",
    "filesleg = [fn for fn in glob.glob('/ESS_Datasets/USERS/Marco/rasters/NA/dynamic/*.tif') if\n",
    " 'pop' not in os.path.basename(fn) and 'suppressionp' not in os.path.basename(fn) and 'ignitionp' not in os.path.basename(fn)]\n",
    "\n",
    "# Loop through raster files\n",
    "for filer in filesleg:\n",
    "    # open raster with rasterio\n",
    "    tmpr = rst.open(filer)\n",
    "    # get out names for variable of interest\n",
    "    varnametmp = os.path.basename(filer).split('.')[0]\n",
    "    varname = varnametmp.split('_')[0] + \"_\" + varnametmp.split('_')[1] + \"_\" + varnametmp.split('_')[3]\n",
    "    # parse numbers (could be year, resolution or season!)\n",
    "    numbs = re.findall('\\d+', os.path.basename(filer).split('.')[0])\n",
    "    # extract the number with the longest number of digits\n",
    "    year = max(numbs, key=len)\n",
    "    if int(year) < 2000:\n",
    "        pass\n",
    "    else:\n",
    "        #------- Year-1\n",
    "        year_m1 = str(int(year) - 1)\n",
    "        # path for raster year -1\n",
    "        fpathym1 = '/ESS_Datasets/USERS/Marco/rasters/NA/dynamic/' + str.replace(varnametmp, year, year_m1) + '.tif'\n",
    "        # open raster with rasterio\n",
    "        tmpr = rst.open(fpathym1)\n",
    "        # convert into array\n",
    "        tmpar = tmpr.read(1)\n",
    "        # if integer convert into floating point\n",
    "        # get transformation parameter (needed for zonal stats)\n",
    "        affine = tmpr.transform\n",
    "        # match year with polygon\n",
    "        for filep in results_final:\n",
    "            # create year filter\n",
    "            if (str(int(filep.YEAR.unique()[0])) == year):\n",
    "                # zonal statistics (mean)\n",
    "                stats = zonal_stats(filep, tmpar, affine=affine, stats=['mean'], all_touched=True,  nodata=tmpr.nodata)\n",
    "                # convert dictionaries into lists\n",
    "                stats1 = [val for dic in stats for val in dic.values()]\n",
    "                # store in pandas dataframe\n",
    "                filep[varname + '_ym1'] = stats1\n",
    "        # ------- Year-2\n",
    "        year_m2 = str(int(year) - 2)\n",
    "        # path for raster year -1\n",
    "        fpathym2 = '/ESS_Datasets/USERS/Marco/rasters/NA/dynamic/' + str.replace(varnametmp, year, year_m2) + '.tif'\n",
    "        # open raster with rasterio\n",
    "        tmpr = rst.open(fpathym2)\n",
    "        # convert into array\n",
    "        tmpar = tmpr.read(1)\n",
    "        # if integer convert into floating point\n",
    "        # get transformation parameter (needed for zonal stats)\n",
    "        affine = tmpr.transform\n",
    "        # match year with polygon\n",
    "        for filep in results_final:\n",
    "            # create year filter\n",
    "            if (str(int(filep.YEAR.unique()[0])) == year):\n",
    "                # zonal statistics (mean)\n",
    "                stats = zonal_stats(filep, tmpar, affine=affine, stats=['mean'], all_touched=True, nodata=tmpr.nodata)\n",
    "                # convert dictionaries into lists\n",
    "                stats1 = [val for dic in stats for val in dic.values()]\n",
    "                # store in pandas dataframe\n",
    "                filep[varname + '_ym2'] = stats1\n",
    "        # ------- Year-3\n",
    "        year_m3 = str(int(year) - 3)\n",
    "        # path for raster year -1\n",
    "        fpathym3 = '/ESS_Datasets/USERS/Marco/rasters/NA/dynamic/' + str.replace(varnametmp, year, year_m3) + '.tif'\n",
    "        # open raster with rasterio\n",
    "        tmpr = rst.open(fpathym3)\n",
    "        # convert into array\n",
    "        tmpar = tmpr.read(1)\n",
    "        # if integer convert into floating point\n",
    "        # get transformation parameter (needed for zonal stats)\n",
    "        affine = tmpr.transform\n",
    "        # match year with polygon\n",
    "        for filep in results_final:\n",
    "            # create year filter\n",
    "            if (str(int(filep.YEAR.unique()[0])) == year):\n",
    "                # zonal statistics (mean)\n",
    "                stats = zonal_stats(filep, tmpar, affine=affine, stats=['mean'], all_touched=True, nodata=tmpr.nodata)\n",
    "                # convert dictionaries into lists\n",
    "                stats1 = [val for dic in stats for val in dic.values()]\n",
    "                # store in pandas dataframe\n",
    "                filep[varname + '_ym3'] = stats1\n",
    "        # ------- Year-4\n",
    "        year_m4 = str(int(year) - 4)\n",
    "        # path for raster year -1\n",
    "        fpathym4 = '/ESS_Datasets/USERS/Marco/rasters/NA/dynamic/' + str.replace(varnametmp, year, year_m4) + '.tif'\n",
    "        # open raster with rasterio\n",
    "        tmpr = rst.open(fpathym4)\n",
    "        # convert into array\n",
    "        tmpar = tmpr.read(1)\n",
    "        # if integer convert into floating point\n",
    "        # get transformation parameter (needed for zonal stats)\n",
    "        affine = tmpr.transform\n",
    "        # match year with polygon\n",
    "        for filep in results_final:\n",
    "            # create year filter\n",
    "            if (str(int(filep.YEAR.unique()[0])) == year):\n",
    "                # zonal statistics (mean)\n",
    "                stats = zonal_stats(filep, tmpar, affine=affine, stats=['mean'], all_touched=True, nodata=tmpr.nodata)\n",
    "                # convert dictionaries into lists\n",
    "                stats1 = [val for dic in stats for val in dic.values()]\n",
    "                # store in pandas dataframe\n",
    "                filep[varname + '_ym4'] = stats1\n",
    "        # ------- Year-5\n",
    "        year_m5 = str(int(year) - 5)\n",
    "        # path for raster year -1\n",
    "        fpathym5 = '/ESS_Datasets/USERS/Marco/rasters/NA/dynamic/' + str.replace(varnametmp, year, year_m5) + '.tif'\n",
    "        # open raster with rasterio\n",
    "        tmpr = rst.open(fpathym5)\n",
    "        # convert into array\n",
    "        tmpar = tmpr.read(1)\n",
    "        # if integer convert into floating point\n",
    "        # get transformation parameter (needed for zonal stats)\n",
    "        affine = tmpr.transform\n",
    "        # match year with polygon\n",
    "        for filep in results_final:\n",
    "            # create year filter\n",
    "            if (str(int(filep.YEAR.unique()[0])) == year):\n",
    "                # zonal statistics (mean)\n",
    "                stats = zonal_stats(filep, tmpar, affine=affine, stats=['mean'], all_touched=True, nodata=tmpr.nodata)\n",
    "                # convert dictionaries into lists\n",
    "                stats1 = [val for dic in stats for val in dic.values()]\n",
    "                # store in pandas dataframe\n",
    "                filep[varname + '_ym5'] = stats1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate list of pandas dataframes\n",
    "results_final1 = pd.concat(results_final)\n",
    "# delete geometry column\n",
    "results_final1 = results_final1.drop(['geometry'], axis=1)\n",
    "# write results as csv file\n",
    "results_final1.to_csv('/home/marco/Desktop/INSECT_OBSERVED.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
